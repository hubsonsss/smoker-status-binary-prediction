{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using unpreprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     0\n",
      "age                    0\n",
      "height(cm)             0\n",
      "weight(kg)             0\n",
      "waist(cm)              0\n",
      "eyesight(left)         0\n",
      "eyesight(right)        0\n",
      "hearing(left)          0\n",
      "hearing(right)         0\n",
      "systolic               0\n",
      "relaxation             0\n",
      "fasting blood sugar    0\n",
      "Cholesterol            0\n",
      "triglyceride           0\n",
      "HDL                    0\n",
      "LDL                    0\n",
      "hemoglobin             0\n",
      "Urine protein          0\n",
      "serum creatinine       0\n",
      "AST                    0\n",
      "ALT                    0\n",
      "Gtp                    0\n",
      "dental caries          0\n",
      "smoking                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Fill missing values or drop them\n",
    "train_data.fillna(train_data.median(), inplace=True)\n",
    "\n",
    "# Encoding categorical variables if necessary\n",
    "# Here, I'm assuming there are categorical variables. Adjust as per your dataset.\n",
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "# Ensure train and test data have the same columns\n",
    "# train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('smoking', axis=1)\n",
    "y = train_data['smoking']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 0.38725767399198574\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, y_pred_xgb))\n",
    "print(f'XGBoost RMSE: {xgb_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     22\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[0;32m     29\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_xgb_model = XGBRegressor(**best_params, random_state=42)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_xgb_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - 0.80623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 - 5s - 1ms/step - AUC: 0.5791 - loss: 25.4712 - val_AUC: 0.6353 - val_loss: 5.3111\n",
      "Epoch 2/100\n",
      "3982/3982 - 4s - 931us/step - AUC: 0.6295 - loss: 5.8477 - val_AUC: 0.7828 - val_loss: 1.4889\n",
      "Epoch 3/100\n",
      "3982/3982 - 4s - 909us/step - AUC: 0.6478 - loss: 4.3028 - val_AUC: 0.5896 - val_loss: 6.2866\n",
      "Epoch 4/100\n",
      "3982/3982 - 4s - 920us/step - AUC: 0.6593 - loss: 2.8470 - val_AUC: 0.6928 - val_loss: 2.1983\n",
      "Epoch 5/100\n",
      "3982/3982 - 4s - 902us/step - AUC: 0.6697 - loss: 1.7914 - val_AUC: 0.6107 - val_loss: 2.8768\n",
      "Epoch 6/100\n",
      "3982/3982 - 4s - 906us/step - AUC: 0.6945 - loss: 1.1439 - val_AUC: 0.7955 - val_loss: 0.5918\n",
      "Epoch 7/100\n",
      "3982/3982 - 4s - 909us/step - AUC: 0.6996 - loss: 0.6693 - val_AUC: 0.5453 - val_loss: 0.6778\n",
      "Epoch 8/100\n",
      "3982/3982 - 4s - 908us/step - AUC: 0.5928 - loss: 0.6743 - val_AUC: 0.5315 - val_loss: 0.6778\n",
      "Epoch 9/100\n",
      "3982/3982 - 4s - 891us/step - AUC: 0.5335 - loss: 0.6777 - val_AUC: 0.5187 - val_loss: 0.6817\n",
      "Epoch 10/100\n",
      "3982/3982 - 4s - 907us/step - AUC: 0.5130 - loss: 0.6811 - val_AUC: 0.5179 - val_loss: 0.6817\n",
      "Epoch 11/100\n",
      "3982/3982 - 4s - 904us/step - AUC: 0.5083 - loss: 0.6863 - val_AUC: 0.5100 - val_loss: 0.6841\n",
      "Epoch 12/100\n",
      "3982/3982 - 4s - 906us/step - AUC: 0.5164 - loss: 0.6814 - val_AUC: 0.5161 - val_loss: 0.6825\n",
      "Epoch 13/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5204 - loss: 0.6816 - val_AUC: 0.5123 - val_loss: 0.6834\n",
      "Epoch 14/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5199 - loss: 0.6818 - val_AUC: 0.5143 - val_loss: 0.6829\n",
      "Epoch 15/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5100 - loss: 0.6824 - val_AUC: 0.5097 - val_loss: 0.6839\n",
      "Epoch 16/100\n",
      "3982/3982 - 4s - 933us/step - AUC: 0.5247 - loss: 0.6881 - val_AUC: 0.5360 - val_loss: 0.6761\n",
      "\u001b[1m996/996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step\n",
      "Neural Network ROC AUC: 0.7955519927738477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(22, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159256</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>49</td>\n",
       "      <td>115</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159257</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>35</td>\n",
       "      <td>104</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159258</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>70</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>39</td>\n",
       "      <td>88</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159259</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>75</td>\n",
       "      <td>128</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159260</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>89.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106166</th>\n",
       "      <td>265422</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>149</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106167</th>\n",
       "      <td>265423</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>85</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>44</td>\n",
       "      <td>100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106168</th>\n",
       "      <td>265424</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>85</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>142</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106169</th>\n",
       "      <td>265425</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106170</th>\n",
       "      <td>265426</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106171 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0       159256   40         165          70       84.0             1.2   \n",
       "1       159257   80         160          60       93.0             1.0   \n",
       "2       159258   60         170          70       86.5             0.6   \n",
       "3       159259   40         160          50       67.0             0.3   \n",
       "4       159260   40         170          75       89.4             1.0   \n",
       "...        ...  ...         ...         ...        ...             ...   \n",
       "106166  265422   40         165          60       78.0             0.8   \n",
       "106167  265423   40         170          85       95.0             1.2   \n",
       "106168  265424   35         170          85       89.0             1.2   \n",
       "106169  265425   40         160          60       67.0             0.7   \n",
       "106170  265426   50         150          50       80.0             0.9   \n",
       "\n",
       "        eyesight(right)  hearing(left)  hearing(right)  systolic  ...  \\\n",
       "0                   1.2              1               1       130  ...   \n",
       "1                   1.0              2               2       144  ...   \n",
       "2                   0.7              1               1       117  ...   \n",
       "3                   0.4              1               1       116  ...   \n",
       "4                   0.9              1               1       132  ...   \n",
       "...                 ...            ...             ...       ...  ...   \n",
       "106166              0.9              1               1       112  ...   \n",
       "106167              1.2              1               1       130  ...   \n",
       "106168              1.2              1               1       131  ...   \n",
       "106169              0.8              1               1       120  ...   \n",
       "106170              1.0              1               1       115  ...   \n",
       "\n",
       "        triglyceride  HDL  LDL  hemoglobin  Urine protein  serum creatinine  \\\n",
       "0                186   49  115        14.2              1               0.9   \n",
       "1                158   35  104        13.0              1               1.1   \n",
       "2                173   39   88        15.4              1               1.4   \n",
       "3                 47   75  128        14.5              1               0.6   \n",
       "4                100   39  123        16.5              1               1.0   \n",
       "...              ...  ...  ...         ...            ...               ...   \n",
       "106166            82   59  149        16.4              1               1.1   \n",
       "106167           186   44  100        16.0              2               1.0   \n",
       "106168            76   53  142        15.9              1               0.8   \n",
       "106169            81   55  103        13.9              1               0.6   \n",
       "106170            96   48  144        13.0              1               0.6   \n",
       "\n",
       "        AST  ALT  Gtp  dental caries  \n",
       "0        19   25   32              0  \n",
       "1        20   12   24              0  \n",
       "2        38   60   36              0  \n",
       "3        25   18   10              1  \n",
       "4        30   39   27              1  \n",
       "...     ...  ...  ...            ...  \n",
       "106166   24   31   28              0  \n",
       "106167   25   31   38              0  \n",
       "106168   33   32   24              1  \n",
       "106169   42   36   32              0  \n",
       "106170   18   11   17              1  \n",
       "\n",
       "[106171 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 609us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - 0.83979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 - 8s - 2ms/step - AUC: 0.6268 - loss: 0.6707 - val_AUC: 0.8002 - val_loss: 0.5510 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7553 - loss: 0.5759 - val_AUC: 0.8159 - val_loss: 0.5127 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.7785 - loss: 0.5531 - val_AUC: 0.7961 - val_loss: 0.5891 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7860 - loss: 0.5439 - val_AUC: 0.8061 - val_loss: 0.5647 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7917 - loss: 0.5383 - val_AUC: 0.7962 - val_loss: 0.7078 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7948 - loss: 0.5338 - val_AUC: 0.8258 - val_loss: 0.4954 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.7976 - loss: 0.5302 - val_AUC: 0.8262 - val_loss: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8010 - loss: 0.5263 - val_AUC: 0.8216 - val_loss: 0.5338 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8024 - loss: 0.5247 - val_AUC: 0.8028 - val_loss: 0.6520 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8037 - loss: 0.5231 - val_AUC: 0.8265 - val_loss: 0.5054 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8045 - loss: 0.5219 - val_AUC: 0.8260 - val_loss: 0.5135 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8106 - loss: 0.5124 - val_AUC: 0.8270 - val_loss: 0.5008 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8113 - loss: 0.5114 - val_AUC: 0.8289 - val_loss: 0.4929 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8123 - loss: 0.5107 - val_AUC: 0.8225 - val_loss: 0.5192 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8127 - loss: 0.5102 - val_AUC: 0.8292 - val_loss: 0.4955 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8122 - loss: 0.5105 - val_AUC: 0.8285 - val_loss: 0.4971 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8132 - loss: 0.5099 - val_AUC: 0.8270 - val_loss: 0.5037 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8129 - loss: 0.5105 - val_AUC: 0.8263 - val_loss: 0.5081 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8134 - loss: 0.5088 - val_AUC: 0.8297 - val_loss: 0.4919 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8146 - loss: 0.5080 - val_AUC: 0.8301 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8148 - loss: 0.5068 - val_AUC: 0.8254 - val_loss: 0.5164 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8143 - loss: 0.5075 - val_AUC: 0.8302 - val_loss: 0.4918 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8151 - loss: 0.5071 - val_AUC: 0.8301 - val_loss: 0.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8144 - loss: 0.5079 - val_AUC: 0.8304 - val_loss: 0.4896 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8148 - loss: 0.5072 - val_AUC: 0.8298 - val_loss: 0.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8148 - loss: 0.5073 - val_AUC: 0.8296 - val_loss: 0.4976 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8156 - loss: 0.5063 - val_AUC: 0.8298 - val_loss: 0.4907 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8152 - loss: 0.5065 - val_AUC: 0.8297 - val_loss: 0.4940 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8153 - loss: 0.5063 - val_AUC: 0.8306 - val_loss: 0.4895 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8165 - loss: 0.5044 - val_AUC: 0.8307 - val_loss: 0.4918 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8160 - loss: 0.5056 - val_AUC: 0.8308 - val_loss: 0.4911 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8159 - loss: 0.5054 - val_AUC: 0.8307 - val_loss: 0.4903 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8161 - loss: 0.5053 - val_AUC: 0.8309 - val_loss: 0.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8163 - loss: 0.5059 - val_AUC: 0.8294 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8157 - loss: 0.5057 - val_AUC: 0.8313 - val_loss: 0.4897 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5044 - val_AUC: 0.8315 - val_loss: 0.4894 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8163 - loss: 0.5057 - val_AUC: 0.8311 - val_loss: 0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8160 - loss: 0.5049 - val_AUC: 0.8319 - val_loss: 0.4888 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8164 - loss: 0.5052 - val_AUC: 0.8320 - val_loss: 0.4875 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5048 - val_AUC: 0.8319 - val_loss: 0.4893 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8172 - loss: 0.5041 - val_AUC: 0.8318 - val_loss: 0.4885 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8180 - loss: 0.5032 - val_AUC: 0.8317 - val_loss: 0.4893 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8178 - loss: 0.5037 - val_AUC: 0.8314 - val_loss: 0.4895 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8179 - loss: 0.5032 - val_AUC: 0.8303 - val_loss: 0.4922 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8191 - loss: 0.5014 - val_AUC: 0.8305 - val_loss: 0.4943 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5042 - val_AUC: 0.8327 - val_loss: 0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8179 - loss: 0.5036 - val_AUC: 0.8334 - val_loss: 0.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8185 - loss: 0.5027 - val_AUC: 0.8332 - val_loss: 0.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8183 - loss: 0.5026 - val_AUC: 0.8334 - val_loss: 0.4864 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8191 - loss: 0.5022 - val_AUC: 0.8336 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8194 - loss: 0.5011 - val_AUC: 0.8332 - val_loss: 0.4868 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8196 - loss: 0.5009 - val_AUC: 0.8323 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8185 - loss: 0.5026 - val_AUC: 0.8320 - val_loss: 0.4949 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8186 - loss: 0.5029 - val_AUC: 0.8318 - val_loss: 0.4903 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8204 - loss: 0.5009 - val_AUC: 0.8331 - val_loss: 0.4917 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5012 - val_AUC: 0.8342 - val_loss: 0.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8202 - loss: 0.5005 - val_AUC: 0.8349 - val_loss: 0.4840 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8204 - loss: 0.5005 - val_AUC: 0.8310 - val_loss: 0.5012 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8194 - loss: 0.5015 - val_AUC: 0.8345 - val_loss: 0.4845 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8212 - loss: 0.4996 - val_AUC: 0.8333 - val_loss: 0.4856 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8207 - loss: 0.5004 - val_AUC: 0.8341 - val_loss: 0.4874 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5007 - val_AUC: 0.8348 - val_loss: 0.4835 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8204 - loss: 0.5005 - val_AUC: 0.8297 - val_loss: 0.5040 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8202 - loss: 0.4998 - val_AUC: 0.8318 - val_loss: 0.4908 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8200 - loss: 0.5002 - val_AUC: 0.8353 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5005 - val_AUC: 0.8338 - val_loss: 0.4859 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8207 - loss: 0.4998 - val_AUC: 0.8351 - val_loss: 0.4842 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8219 - loss: 0.4988 - val_AUC: 0.8353 - val_loss: 0.4851 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8197 - loss: 0.5004 - val_AUC: 0.8355 - val_loss: 0.4831 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8221 - loss: 0.4979 - val_AUC: 0.8350 - val_loss: 0.4831 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8212 - loss: 0.4988 - val_AUC: 0.8358 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8215 - loss: 0.4988 - val_AUC: 0.8358 - val_loss: 0.4828 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8212 - loss: 0.4992 - val_AUC: 0.8356 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8214 - loss: 0.4992 - val_AUC: 0.8344 - val_loss: 0.4909 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8218 - loss: 0.4979 - val_AUC: 0.8340 - val_loss: 0.4892 - learning_rate: 1.0000e-04\n",
      "\u001b[1m996/996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step\n",
      "Neural Network ROC AUC: 0.8353039739828398\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AUC', 'loss', 'val_AUC', 'val_loss', 'learning_rate'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation AUC values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['AUC'], label='Train AUC')\n",
    "plt.plot(history.history['val_AUC'], label='Val AUC')\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - ROC - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7803905563229938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79     17783\n",
      "           1       0.73      0.80      0.76     14069\n",
      "\n",
      "    accuracy                           0.78     31852\n",
      "   macro avg       0.78      0.78      0.78     31852\n",
      "weighted avg       0.79      0.78      0.78     31852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the preprocessed csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                    0\n",
      "height(cm)             0\n",
      "weight(kg)             0\n",
      "waist(cm)              0\n",
      "systolic               0\n",
      "relaxation             0\n",
      "fasting blood sugar    0\n",
      "triglyceride           0\n",
      "HDL                    0\n",
      "LDL                    0\n",
      "hemoglobin             0\n",
      "Urine protein          0\n",
      "serum creatinine       0\n",
      "AST                    0\n",
      "ALT                    0\n",
      "Gtp                    0\n",
      "dental caries          0\n",
      "BMI                    0\n",
      "hearing                0\n",
      "eyesight               0\n",
      "AST/ALT_ratio          0\n",
      "smoking                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Fill missing values or drop them\n",
    "train_data.fillna(train_data.median(), inplace=True)\n",
    "\n",
    "# Encoding categorical variables if necessary\n",
    "# Here, I'm assuming there are categorical variables. Adjust as per your dataset.\n",
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "# Ensure train and test data have the same columns\n",
    "# train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('smoking', axis=1)\n",
    "y = train_data['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - NN - ROC - 0.85871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 9s - 2ms/step - AUC: 0.8098 - loss: 0.5155 - val_AUC: 0.8440 - val_loss: 0.4741 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8303 - loss: 0.4894 - val_AUC: 0.8452 - val_loss: 0.4712 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8330 - loss: 0.4868 - val_AUC: 0.8468 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8345 - loss: 0.4847 - val_AUC: 0.8481 - val_loss: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8347 - loss: 0.4839 - val_AUC: 0.8475 - val_loss: 0.4700 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8339 - loss: 0.4851 - val_AUC: 0.8483 - val_loss: 0.4679 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8355 - loss: 0.4837 - val_AUC: 0.8483 - val_loss: 0.4749 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8358 - loss: 0.4833 - val_AUC: 0.8484 - val_loss: 0.4687 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8365 - loss: 0.4820 - val_AUC: 0.8490 - val_loss: 0.4661 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8354 - loss: 0.4836 - val_AUC: 0.8488 - val_loss: 0.4663 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8370 - loss: 0.4815 - val_AUC: 0.8489 - val_loss: 0.4681 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8362 - loss: 0.4823 - val_AUC: 0.8485 - val_loss: 0.4683 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8364 - loss: 0.4822 - val_AUC: 0.8492 - val_loss: 0.4660 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8371 - loss: 0.4814 - val_AUC: 0.8475 - val_loss: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8378 - loss: 0.4803 - val_AUC: 0.8482 - val_loss: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8366 - loss: 0.4815 - val_AUC: 0.8482 - val_loss: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8386 - loss: 0.4796 - val_AUC: 0.8491 - val_loss: 0.4697 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8380 - loss: 0.4802 - val_AUC: 0.8494 - val_loss: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8388 - loss: 0.4792 - val_AUC: 0.8495 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4787 - val_AUC: 0.8495 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8403 - loss: 0.4775 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4786 - val_AUC: 0.8495 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4779 - val_AUC: 0.8495 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4775 - val_AUC: 0.8499 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4785 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4775 - val_AUC: 0.8497 - val_loss: 0.4646 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4775 - val_AUC: 0.8498 - val_loss: 0.4647 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8399 - loss: 0.4780 - val_AUC: 0.8499 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4776 - val_AUC: 0.8498 - val_loss: 0.4648 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8398 - loss: 0.4784 - val_AUC: 0.8498 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8404 - loss: 0.4773 - val_AUC: 0.8496 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8403 - loss: 0.4770 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4776 - val_AUC: 0.8500 - val_loss: 0.4643 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8405 - loss: 0.4773 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8402 - loss: 0.4778 - val_AUC: 0.8500 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8406 - loss: 0.4766 - val_AUC: 0.8499 - val_loss: 0.4644 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4778 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8409 - loss: 0.4769 - val_AUC: 0.8500 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8404 - loss: 0.4768 - val_AUC: 0.8501 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8398 - loss: 0.4778 - val_AUC: 0.8500 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4774 - val_AUC: 0.8499 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8407 - loss: 0.4767 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8406 - loss: 0.4768 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step\n",
      "Neural Network ROC AUC: 0.8500097194665805\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - NN - ROC - 0.85812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 10s - 2ms/step - AUC: 0.8141 - loss: 0.5094 - val_AUC: 0.8403 - val_loss: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8315 - loss: 0.4887 - val_AUC: 0.8471 - val_loss: 0.4692 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8330 - loss: 0.4869 - val_AUC: 0.8463 - val_loss: 0.4712 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8336 - loss: 0.4859 - val_AUC: 0.8474 - val_loss: 0.4688 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8343 - loss: 0.4850 - val_AUC: 0.8479 - val_loss: 0.4710 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8348 - loss: 0.4837 - val_AUC: 0.8475 - val_loss: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8354 - loss: 0.4838 - val_AUC: 0.8484 - val_loss: 0.4770 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8357 - loss: 0.4833 - val_AUC: 0.8471 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8357 - loss: 0.4827 - val_AUC: 0.8477 - val_loss: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8367 - loss: 0.4821 - val_AUC: 0.8488 - val_loss: 0.4672 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8367 - loss: 0.4817 - val_AUC: 0.8490 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8361 - loss: 0.4826 - val_AUC: 0.8481 - val_loss: 0.4682 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8367 - loss: 0.4819 - val_AUC: 0.8482 - val_loss: 0.4674 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8368 - loss: 0.4816 - val_AUC: 0.8492 - val_loss: 0.4675 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8370 - loss: 0.4819 - val_AUC: 0.8488 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8374 - loss: 0.4811 - val_AUC: 0.8490 - val_loss: 0.4659 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8371 - loss: 0.4813 - val_AUC: 0.8496 - val_loss: 0.4656 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8374 - loss: 0.4813 - val_AUC: 0.8492 - val_loss: 0.4668 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8365 - loss: 0.4821 - val_AUC: 0.8487 - val_loss: 0.4677 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8374 - loss: 0.4807 - val_AUC: 0.8483 - val_loss: 0.4758 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8370 - loss: 0.4814 - val_AUC: 0.8489 - val_loss: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8382 - loss: 0.4802 - val_AUC: 0.8488 - val_loss: 0.4767 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8384 - loss: 0.4799 - val_AUC: 0.8494 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8391 - loss: 0.4790 - val_AUC: 0.8495 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8386 - loss: 0.4800 - val_AUC: 0.8494 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8388 - loss: 0.4794 - val_AUC: 0.8493 - val_loss: 0.4656 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8387 - loss: 0.4797 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4790 - val_AUC: 0.8498 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8391 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4782 - val_AUC: 0.8496 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8387 - loss: 0.4792 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8380 - loss: 0.4802 - val_AUC: 0.8495 - val_loss: 0.4653 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4786 - val_AUC: 0.8495 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4791 - val_AUC: 0.8496 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4778 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "4956/4956 - 7s - 2ms/step - AUC: 0.8397 - loss: 0.4781 - val_AUC: 0.8497 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8387 - loss: 0.4798 - val_AUC: 0.8497 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8395 - loss: 0.4788 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4782 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4784 - val_AUC: 0.8497 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "4956/4956 - 7s - 2ms/step - AUC: 0.8394 - loss: 0.4790 - val_AUC: 0.8497 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4783 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8394 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8394 - loss: 0.4785 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4791 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4791 - val_AUC: 0.8497 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4789 - val_AUC: 0.8498 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4789 - val_AUC: 0.8498 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8396 - loss: 0.4784 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step\n",
      "Neural Network ROC AUC: 0.8497395970013535\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 1698736 does not match index length 106171",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_test_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_preprocessed)\n\u001b[1;32m----> 6\u001b[0m submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmoking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred_prob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m         )\n\u001b[1;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 1698736 does not match index length 106171"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_10, built=True>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 32, 16, 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from math import cos, sin, atan\n",
    "\n",
    "\n",
    "class Neuron():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self, neuron_radius):\n",
    "        circle = pyplot.Circle((self.x, self.y), radius=neuron_radius, fill=False)\n",
    "        pyplot.gca().add_patch(circle)\n",
    "\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, network, number_of_neurons, number_of_neurons_in_widest_layer):\n",
    "        self.vertical_distance_between_layers = 6\n",
    "        self.horizontal_distance_between_neurons = 2\n",
    "        self.neuron_radius = 0.5\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.previous_layer = self.__get_previous_layer(network)\n",
    "        self.y = self.__calculate_layer_y_position()\n",
    "        self.neurons = self.__intialise_neurons(number_of_neurons)\n",
    "\n",
    "    def __intialise_neurons(self, number_of_neurons):\n",
    "        neurons = []\n",
    "        x = self.__calculate_left_margin_so_layer_is_centered(number_of_neurons)\n",
    "        for iteration in range(number_of_neurons):\n",
    "            neuron = Neuron(x, self.y)\n",
    "            neurons.append(neuron)\n",
    "            x += self.horizontal_distance_between_neurons\n",
    "        return neurons\n",
    "\n",
    "    def __calculate_left_margin_so_layer_is_centered(self, number_of_neurons):\n",
    "        return self.horizontal_distance_between_neurons * (self.number_of_neurons_in_widest_layer - number_of_neurons) / 2\n",
    "\n",
    "    def __calculate_layer_y_position(self):\n",
    "        if self.previous_layer:\n",
    "            return self.previous_layer.y + self.vertical_distance_between_layers\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __get_previous_layer(self, network):\n",
    "        if len(network.layers) > 0:\n",
    "            return network.layers[-1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __line_between_two_neurons(self, neuron1, neuron2):\n",
    "        angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))\n",
    "        x_adjustment = self.neuron_radius * sin(angle)\n",
    "        y_adjustment = self.neuron_radius * cos(angle)\n",
    "        line = pyplot.Line2D((neuron1.x - x_adjustment, neuron2.x + x_adjustment), (neuron1.y - y_adjustment, neuron2.y + y_adjustment))\n",
    "        pyplot.gca().add_line(line)\n",
    "\n",
    "    def draw(self, layerType=0):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.draw( self.neuron_radius )\n",
    "            if self.previous_layer:\n",
    "                for previous_layer_neuron in self.previous_layer.neurons:\n",
    "                    self.__line_between_two_neurons(neuron, previous_layer_neuron)\n",
    "        # write Text\n",
    "        x_text = self.number_of_neurons_in_widest_layer * self.horizontal_distance_between_neurons\n",
    "        if layerType == 0:\n",
    "            pyplot.text(x_text, self.y, 'Input Layer', fontsize = 12)\n",
    "        elif layerType == -1:\n",
    "            pyplot.text(x_text, self.y, 'Output Layer', fontsize = 12)\n",
    "        else:\n",
    "            pyplot.text(x_text, self.y, 'Hidden Layer '+str(layerType), fontsize = 12)\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, number_of_neurons_in_widest_layer):\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.layers = []\n",
    "        self.layertype = 0\n",
    "\n",
    "    def add_layer(self, number_of_neurons ):\n",
    "        layer = Layer(self, number_of_neurons, self.number_of_neurons_in_widest_layer)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def draw(self):\n",
    "        pyplot.figure()\n",
    "        for i in range( len(self.layers) ):\n",
    "            layer = self.layers[i]\n",
    "            if i == len(self.layers)-1:\n",
    "                i = -1\n",
    "            layer.draw( i )\n",
    "        pyplot.axis('scaled')\n",
    "        pyplot.axis('off')\n",
    "        pyplot.title( 'Neural Network architecture', fontsize=15 )\n",
    "        pyplot.show()\n",
    "\n",
    "class DrawNN():\n",
    "    def __init__( self, neural_network ):\n",
    "        self.neural_network = neural_network\n",
    "\n",
    "    def draw( self ):\n",
    "        widest_layer = max( self.neural_network )\n",
    "        network = NeuralNetwork( widest_layer )\n",
    "        for l in self.neural_network:\n",
    "            network.add_layer(l)\n",
    "        network.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of layers\n",
    "layers = model.layers\n",
    "\n",
    "# Extract the number of neurons for each layer that has neurons\n",
    "layer_neurons = []\n",
    "layers_found = []\n",
    "for layer in layers:\n",
    "    if hasattr(layer, 'units'):\n",
    "        layers_found.append(layer.units)\n",
    "\n",
    "print(layers_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = DrawNN(layers_found)\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m network \u001b[38;5;241m=\u001b[39m DrawNN( [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m1\u001b[39m] )\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 101\u001b[0m, in \u001b[0;36mDrawNN.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m network \u001b[38;5;241m=\u001b[39m NeuralNetwork( widest_layer )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneural_network:\n\u001b[1;32m--> 101\u001b[0m     \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m network\u001b[38;5;241m.\u001b[39mdraw()\n",
      "Cell \u001b[1;32mIn[72], line 78\u001b[0m, in \u001b[0;36mNeuralNetwork.add_layer\u001b[1;34m(self, number_of_neurons)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_layer\u001b[39m(\u001b[38;5;28mself\u001b[39m, number_of_neurons ):\n\u001b[1;32m---> 78\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_neurons_in_widest_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(layer)\n",
      "Cell \u001b[1;32mIn[72], line 23\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, network, number_of_neurons, number_of_neurons_in_widest_layer)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprevious_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_previous_layer(network)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__calculate_layer_y_position()\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__intialise_neurons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_neurons\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[72], line 28\u001b[0m, in \u001b[0;36mLayer.__intialise_neurons\u001b[1;34m(self, number_of_neurons)\u001b[0m\n\u001b[0;32m     26\u001b[0m neurons \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__calculate_left_margin_so_layer_is_centered(number_of_neurons)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[43mxrange\u001b[49m(number_of_neurons):\n\u001b[0;32m     29\u001b[0m     neuron \u001b[38;5;241m=\u001b[39m Neuron(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     30\u001b[0m     neurons\u001b[38;5;241m.\u001b[39mappend(neuron)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "network = DrawNN( [2,8,8,1] )\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - MULTITHREADING - ROC - ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 11s - 2ms/step - AUC: 0.8094 - loss: 0.5170 - val_AUC: 0.8411 - val_loss: 0.4752 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8302 - loss: 0.4898 - val_AUC: 0.8454 - val_loss: 0.4718 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8328 - loss: 0.4865 - val_AUC: 0.8468 - val_loss: 0.4697 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8345 - loss: 0.4842 - val_AUC: 0.8451 - val_loss: 0.4722 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8342 - loss: 0.4849 - val_AUC: 0.8473 - val_loss: 0.4702 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8337 - loss: 0.4854 - val_AUC: 0.8473 - val_loss: 0.4713 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8348 - loss: 0.4841 - val_AUC: 0.8478 - val_loss: 0.4719 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8356 - loss: 0.4829 - val_AUC: 0.8454 - val_loss: 0.4756 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8370 - loss: 0.4812 - val_AUC: 0.8492 - val_loss: 0.4664 - learning_rate: 2.0000e-04\n",
      "Epoch 10/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8377 - loss: 0.4797 - val_AUC: 0.8492 - val_loss: 0.4657 - learning_rate: 2.0000e-04\n",
      "Epoch 11/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8380 - loss: 0.4800 - val_AUC: 0.8496 - val_loss: 0.4656 - learning_rate: 2.0000e-04\n",
      "Epoch 12/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8381 - loss: 0.4800 - val_AUC: 0.8494 - val_loss: 0.4659 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8375 - loss: 0.4808 - val_AUC: 0.8496 - val_loss: 0.4655 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8377 - loss: 0.4798 - val_AUC: 0.8494 - val_loss: 0.4655 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8380 - loss: 0.4801 - val_AUC: 0.8493 - val_loss: 0.4661 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8386 - loss: 0.4794 - val_AUC: 0.8495 - val_loss: 0.4655 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8389 - loss: 0.4789 - val_AUC: 0.8496 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8383 - loss: 0.4799 - val_AUC: 0.8498 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8387 - loss: 0.4793 - val_AUC: 0.8498 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8390 - loss: 0.4789 - val_AUC: 0.8500 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8395 - loss: 0.4783 - val_AUC: 0.8493 - val_loss: 0.4657 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8388 - loss: 0.4789 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8391 - loss: 0.4784 - val_AUC: 0.8496 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8392 - loss: 0.4786 - val_AUC: 0.8496 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8400 - loss: 0.4779 - val_AUC: 0.8499 - val_loss: 0.4655 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8398 - loss: 0.4782 - val_AUC: 0.8499 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8401 - loss: 0.4778 - val_AUC: 0.8499 - val_loss: 0.4653 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8404 - loss: 0.4774 - val_AUC: 0.8500 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8396 - loss: 0.4781 - val_AUC: 0.8501 - val_loss: 0.4653 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8399 - loss: 0.4778 - val_AUC: 0.8500 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8397 - loss: 0.4776 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8402 - loss: 0.4774 - val_AUC: 0.8497 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8400 - loss: 0.4776 - val_AUC: 0.8500 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8407 - loss: 0.4767 - val_AUC: 0.8502 - val_loss: 0.4644 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8406 - loss: 0.4767 - val_AUC: 0.8501 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8411 - loss: 0.4766 - val_AUC: 0.8501 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8395 - loss: 0.4777 - val_AUC: 0.8500 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8407 - loss: 0.4769 - val_AUC: 0.8501 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8399 - loss: 0.4775 - val_AUC: 0.8501 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8405 - loss: 0.4773 - val_AUC: 0.8504 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "4956/4956 - 10s - 2ms/step - AUC: 0.8414 - loss: 0.4760 - val_AUC: 0.8502 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8407 - loss: 0.4772 - val_AUC: 0.8500 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8404 - loss: 0.4775 - val_AUC: 0.8499 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "4956/4956 - 9s - 2ms/step - AUC: 0.8401 - loss: 0.4774 - val_AUC: 0.8500 - val_loss: 0.4654 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step\n",
      "Neural Network ROC AUC: 0.8502568421434241\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Set up the distribution strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with pipeline: config dodaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom transformer to remove columns\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(self.columns_to_drop, axis=1)\n",
    "\n",
    "# Custom transformer to remove outliers\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=3.0):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        z_scores = np.abs((X - X.mean()) / X.std())\n",
    "        return X[(z_scores < self.threshold).all(axis=1)]\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv(\"../data/data_merged.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Define columns to drop (example: 'col1', 'col2')\n",
    "columns_to_drop = ['col1', 'col2']\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('drop_columns', ColumnDropper(columns_to_drop=columns_to_drop)),\n",
    "    ('remove_outliers', OutlierRemover(threshold=3.0)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Split the train dataset into features and target\n",
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "# Preprocess the data\n",
    "X_preprocessed = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/data_merged.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, y, n_sigma):\n",
    "    mask = (np.abs(df - df.mean()) <= (n_sigma * df.std())).all(axis=1)\n",
    "    return df[mask], y[mask]\n",
    "\n",
    "def replace_outliers(df, n_sigma):\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    mask = (np.abs(df - mean) > (n_sigma * std))\n",
    "    df_replaced = df.copy()\n",
    "    for col in df.columns:\n",
    "        col_mask = mask[col]\n",
    "        df_replaced.loc[col_mask, col] = df_replaced.loc[~col_mask, col].ffill().bfill()\n",
    "    return df_replaced\n",
    "\n",
    "def drop_columns(df, columns_to_drop):\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Model definitions\n",
    "def create_neural_network(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    predictions = model.predict(X_val).ravel()\n",
    "    return roc_auc_score(y_val, predictions)\n",
    "\n",
    "def save_preprocessed_data(X, y, sigma, columns_to_drop, method):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs('./preprocessed', exist_ok=True)\n",
    "    \n",
    "    # Combine X and y into a single DataFrame\n",
    "    data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    data['target'] = y.values\n",
    "    \n",
    "    # Construct the filename\n",
    "    filename = f'preprocessed_sigma{sigma}_drop{len(columns_to_drop)}_{method}.csv'\n",
    "    \n",
    "    # Save the dataframe as a CSV file\n",
    "    data.to_csv(f'./preprocessed/{filename}', index=False)\n",
    "\n",
    "def plot_distributions(data, sigma, columns_to_drop, method):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    num_vars = data.shape[1]\n",
    "    for i, column in enumerate(data.columns):\n",
    "        plt.subplot((num_vars // 3) + 1, 3, i + 1)\n",
    "        sns.histplot(data[column], kde=True)\n",
    "        plt.title(column)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'distribution_sigma{sigma}_drop{len(columns_to_drop)}_{method}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting values to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_values = [1, 2, 3, 4]\n",
    "columns_to_drop_list = [\n",
    "    ['hearing(left)', 'hearing(right)', 'eyesight(left)', 'eyesight(right)', 'Cholesterol'],\n",
    "    ['hearing(left)', 'hearing(right)', 'eyesight(left)', 'eyesight(right)']\n",
    "]\n",
    "outlier_methods = ['drop', 'replace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['smoking'])  # Assuming 'target' is the label column\n",
    "y = train['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in sigma_values:\n",
    "    for columns_to_drop in columns_to_drop_list:\n",
    "        for method in outlier_methods:\n",
    "            # Preprocessing\n",
    "            if method == 'drop':\n",
    "                X_processed, y_processed = remove_outliers(X, y, sigma)\n",
    "            elif method == 'replace':\n",
    "                X_processed = replace_outliers(X, sigma)\n",
    "                y_processed = y[X_processed.index]\n",
    "\n",
    "            X_processed = drop_columns(X_processed, columns_to_drop)\n",
    "            save_preprocessed_data(X_processed, y_processed, sigma, columns_to_drop, method)\n",
    "\n",
    "            # Standardization\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_processed)\n",
    "            \n",
    "            preprocessed_data.append((X_scaled, y_processed, sigma, columns_to_drop, scaler, method))\n",
    "            \n",
    "            # Plotting distributions\n",
    "            plot_distributions(pd.DataFrame(X_scaled, columns=X_processed.columns), sigma, columns_to_drop, method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(data, sigma, columns_to_drop):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    num_vars = data.shape[1]\n",
    "    for i, column in enumerate(data.columns):\n",
    "        plt.subplot((num_vars // 3) + 1, 3, i + 1)\n",
    "        sns.histplot(data[column], kde=True)\n",
    "        plt.title(column)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'distribution_sigma{sigma}_drop{len(columns_to_drop)}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in sigma_values:\n",
    "    for columns_to_drop in columns_to_drop_list:\n",
    "        # Preprocessing\n",
    "        X_processed, y_processed = remove_outliers(X, y, sigma)\n",
    "        X_processed = drop_columns(X_processed, columns_to_drop)\n",
    "        save_preprocessed_data((X_processed, y_processed), f'preprocessed_data_sigma{sigma}_drop{len(columns_to_drop)}.pkl')\n",
    "\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_processed)\n",
    "        \n",
    "        preprocessed_data.append((X_scaled, y_processed, sigma, columns_to_drop, scaler))\n",
    "        \n",
    "        # Plotting distributions\n",
    "        plot_distributions(pd.DataFrame(X_scaled, columns=X_processed.columns), sigma, columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Neural Network\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model_nn \u001b[38;5;241m=\u001b[39m create_neural_network(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m auc_nn \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m'\u001b[39m, sigma, columns_to_drop, auc_nn))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, X_train, y_train, X_val, y_val):\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m roc_auc_score(y_val, predictions)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model building and evaluation step\n",
    "results = []\n",
    "\n",
    "for X_scaled, y_processed, sigma, columns_to_drop, scaler in preprocessed_data:\n",
    "    # Train-test split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Neural Network\n",
    "    model_nn = create_neural_network(X_train.shape[1])\n",
    "    auc_nn = evaluate_model(model_nn, X_train, y_train, X_val, y_val)\n",
    "    results.append(('NN', sigma, columns_to_drop, auc_nn))\n",
    "\n",
    "    # Random Forest\n",
    "    model_rf = RandomForestClassifier()\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    predictions_rf = model_rf.predict_proba(X_val)[:, 1]\n",
    "    auc_rf = roc_auc_score(y_val, predictions_rf)\n",
    "    results.append(('RF', sigma, columns_to_drop, auc_rf))\n",
    "\n",
    "    # Logistic Regression\n",
    "    model_lr = LogisticRegression(max_iter=1000)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    predictions_lr = model_lr.predict_proba(X_val)[:, 1]\n",
    "    auc_lr = roc_auc_score(y_val, predictions_lr)\n",
    "    results.append(('LR', sigma, columns_to_drop, auc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"Model: {result[0]}, Sigma: {result[1]}, Columns Dropped: {result[2]}, AUC: {result[3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Ensure TensorFlow uses GPU if available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 - 4s - 3ms/step - AUC: 0.7918 - loss: 0.5391 - val_AUC: 0.8292 - val_loss: 0.4938 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8172 - loss: 0.5064 - val_AUC: 0.8327 - val_loss: 0.4891 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8228 - loss: 0.5000 - val_AUC: 0.8348 - val_loss: 0.4869 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8255 - loss: 0.4970 - val_AUC: 0.8356 - val_loss: 0.4854 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "1363/1363 - 2s - 2ms/step - AUC: 0.8273 - loss: 0.4955 - val_AUC: 0.8364 - val_loss: 0.4847 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "1363/1363 - 2s - 2ms/step - AUC: 0.8278 - loss: 0.4947 - val_AUC: 0.8375 - val_loss: 0.4838 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "1363/1363 - 2s - 2ms/step - AUC: 0.8281 - loss: 0.4939 - val_AUC: 0.8370 - val_loss: 0.4845 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8297 - loss: 0.4929 - val_AUC: 0.8380 - val_loss: 0.4836 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8290 - loss: 0.4925 - val_AUC: 0.8385 - val_loss: 0.4826 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8302 - loss: 0.4917 - val_AUC: 0.8380 - val_loss: 0.4833 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8313 - loss: 0.4903 - val_AUC: 0.8386 - val_loss: 0.4835 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8311 - loss: 0.4906 - val_AUC: 0.8391 - val_loss: 0.4822 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8312 - loss: 0.4903 - val_AUC: 0.8389 - val_loss: 0.4828 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8318 - loss: 0.4898 - val_AUC: 0.8391 - val_loss: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8318 - loss: 0.4901 - val_AUC: 0.8394 - val_loss: 0.4817 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8319 - loss: 0.4901 - val_AUC: 0.8390 - val_loss: 0.4826 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8322 - loss: 0.4891 - val_AUC: 0.8394 - val_loss: 0.4814 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8332 - loss: 0.4888 - val_AUC: 0.8394 - val_loss: 0.4822 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8328 - loss: 0.4885 - val_AUC: 0.8395 - val_loss: 0.4819 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8314 - loss: 0.4899 - val_AUC: 0.8394 - val_loss: 0.4820 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8343 - loss: 0.4869 - val_AUC: 0.8397 - val_loss: 0.4814 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "1363/1363 - 2s - 2ms/step - AUC: 0.8340 - loss: 0.4866 - val_AUC: 0.8398 - val_loss: 0.4810 - learning_rate: 2.0000e-04\n",
      "Epoch 23/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8341 - loss: 0.4866 - val_AUC: 0.8399 - val_loss: 0.4808 - learning_rate: 2.0000e-04\n",
      "Epoch 24/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8346 - loss: 0.4860 - val_AUC: 0.8400 - val_loss: 0.4807 - learning_rate: 2.0000e-04\n",
      "Epoch 25/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8352 - loss: 0.4859 - val_AUC: 0.8400 - val_loss: 0.4808 - learning_rate: 2.0000e-04\n",
      "Epoch 26/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8346 - loss: 0.4871 - val_AUC: 0.8401 - val_loss: 0.4804 - learning_rate: 2.0000e-04\n",
      "Epoch 27/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8356 - loss: 0.4853 - val_AUC: 0.8403 - val_loss: 0.4805 - learning_rate: 2.0000e-04\n",
      "Epoch 28/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8355 - loss: 0.4847 - val_AUC: 0.8402 - val_loss: 0.4807 - learning_rate: 2.0000e-04\n",
      "Epoch 29/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8356 - loss: 0.4858 - val_AUC: 0.8403 - val_loss: 0.4805 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8356 - loss: 0.4854 - val_AUC: 0.8403 - val_loss: 0.4807 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1363/1363 - 2s - 1ms/step - AUC: 0.8347 - loss: 0.4864 - val_AUC: 0.8402 - val_loss: 0.4805 - learning_rate: 1.0000e-04\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step\n",
      "Neural Network ROC AUC: 0.8401340950624407\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', dtype='float32'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=64,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on multiple csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# # Custom callback to update tqdm progress bar\n",
    "# class TQDMProgressCallback(Callback):\n",
    "#     def __init__(self, tqdm_instance, file):\n",
    "#         super().__init__()\n",
    "#         self.tqdm_instance = tqdm_instance\n",
    "#         self.file = file\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         logs = logs or {}\n",
    "#         self.tqdm_instance.set_description(f\"Processing {self.file} | Epoch {epoch+1} | Loss: {logs.get('loss'):.4f} | AUC: {logs.get('auc'):.4f} | Val_Loss: {logs.get('val_loss'):.4f} | Val_AUC: {logs.get('val_auc'):.4f}\")\n",
    "#         self.tqdm_instance.update(1)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(file):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(f'./preprocessed/{file}')\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "    \n",
    "    # Define early stopping and learning rate reduction callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "    \n",
    "    # Train the model with tqdm progress bar\n",
    "    epochs = 50\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=64,\n",
    "                            validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    \n",
    "    # Save the model\n",
    "    model_filename = f'./models/{os.path.splitext(file)[0]}.h5'\n",
    "    model.save(model_filename)\n",
    "    \n",
    "    # Update the main progress queue with the result\n",
    "    # progress_queue.put((file, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # List all CSV files in the preprocessed directory\n",
    "    preprocessed_dir = './preprocessed/'\n",
    "    files = [f for f in os.listdir(preprocessed_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # Create a manager to handle progress tracking\n",
    "    manager = Manager()\n",
    "    progress_queue = manager.Queue()\n",
    "    \n",
    "    # Add initial position indexes to the queue\n",
    "    # for idx in range(len(files)):\n",
    "    #     progress_queue.put(idx)\n",
    "    \n",
    "    for file in files:\n",
    "        print(f\"Using {file} as the input file.\")\n",
    "        train_model(file)\n",
    "    \n",
    "    # Print the results\n",
    "    for file, roc_auc in results:\n",
    "        print(f'File: {file}, Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma1_drop4_drop.csv as the input file.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - AUC: 0.4831 - loss: 0.6913 - val_AUC: 0.5000 - val_loss: 0.6898 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4897 - loss: 0.6844 - val_AUC: 0.5000 - val_loss: 0.6885 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.5275 - loss: 0.6870 - val_AUC: 0.5000 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4806 - loss: 0.6798 - val_AUC: 0.5000 - val_loss: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4862 - loss: 0.6777 - val_AUC: 0.5000 - val_loss: 0.6895 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.4795 - loss: 0.6823 - val_AUC: 0.5000 - val_loss: 0.6895 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5147 - loss: 0.6813 - val_AUC: 0.5000 - val_loss: 0.6896 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4774 - loss: 0.6850 - val_AUC: 0.5000 - val_loss: 0.6895 - learning_rate: 2.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma1_drop4_replace.csv as the input file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.4984 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4956 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4993 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4981 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4989 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4983 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4974 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5006 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma1_drop5_drop.csv as the input file.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - AUC: 0.4991 - loss: 0.6916 - val_AUC: 0.5000 - val_loss: 0.6900 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.4757 - loss: 0.6892 - val_AUC: 0.5000 - val_loss: 0.6888 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.4962 - loss: 0.6844 - val_AUC: 0.5000 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.5079 - loss: 0.6789 - val_AUC: 0.5000 - val_loss: 0.6888 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.5036 - loss: 0.6852 - val_AUC: 0.5000 - val_loss: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.5014 - loss: 0.6818 - val_AUC: 0.5000 - val_loss: 0.6896 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.4665 - loss: 0.6798 - val_AUC: 0.5000 - val_loss: 0.6896 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - AUC: 0.5327 - loss: 0.6819 - val_AUC: 0.5000 - val_loss: 0.6896 - learning_rate: 2.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma1_drop5_replace.csv as the input file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5000 - loss: 0.6820 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5011 - loss: 0.6809 - val_AUC: 0.5000 - val_loss: 0.6831 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4976 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4987 - loss: 0.6809 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5008 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma2_drop4_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - AUC: 0.5024 - loss: 0.6877 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4947 - loss: 0.6881 - val_AUC: 0.5000 - val_loss: 0.6878 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4971 - loss: 0.6872 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4989 - loss: 0.6874 - val_AUC: 0.5000 - val_loss: 0.6879 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4977 - loss: 0.6868 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5024 - loss: 0.6866 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4988 - loss: 0.6873 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5007 - loss: 0.6869 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4994 - loss: 0.6869 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4996 - loss: 0.6871 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4975 - loss: 0.6873 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5019 - loss: 0.6863 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 1.0000e-04\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma2_drop4_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5000 - loss: 0.6820 - val_AUC: 0.5000 - val_loss: 0.6830 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4999 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4996 - loss: 0.6809 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5017 - loss: 0.6813 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4977 - loss: 0.6809 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4972 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4990 - loss: 0.6809 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma2_drop5_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - AUC: 0.5012 - loss: 0.6873 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4998 - loss: 0.6875 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4998 - loss: 0.6874 - val_AUC: 0.5000 - val_loss: 0.6878 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4961 - loss: 0.6871 - val_AUC: 0.5000 - val_loss: 0.6879 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4980 - loss: 0.6870 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4999 - loss: 0.6871 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4955 - loss: 0.6878 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4992 - loss: 0.6872 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - AUC: 0.4976 - loss: 0.6874 - val_AUC: 0.5000 - val_loss: 0.6876 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1363/1363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - AUC: 0.4997 - loss: 0.6874 - val_AUC: 0.5000 - val_loss: 0.6877 - learning_rate: 1.0000e-04\n",
      "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma2_drop5_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - AUC: 0.5012 - loss: 0.6823 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.5021 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4967 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5040 - loss: 0.6805 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5032 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4977 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5006 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma3_drop4_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.4970 - loss: 0.6819 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4990 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6810 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5009 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5002 - loss: 0.6806 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - AUC: 0.4975 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4976 - loss: 0.6813 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4979 - loss: 0.6806 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4974 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma3_drop4_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4997 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5000 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5020 - loss: 0.6823 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4968 - loss: 0.6815 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma3_drop5_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5031 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5014 - loss: 0.6807 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4982 - loss: 0.6803 - val_AUC: 0.5000 - val_loss: 0.6810 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - AUC: 0.5020 - loss: 0.6807 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4999 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4998 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5018 - loss: 0.6794 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4987 - loss: 0.6806 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5008 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4977 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - AUC: 0.4976 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4996 - loss: 0.6803 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6813 - val_AUC: 0.5000 - val_loss: 0.6809 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma3_drop5_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5028 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4976 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4987 - loss: 0.6814 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4987 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5004 - loss: 0.6807 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4997 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma4_drop4_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.6830 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4970 - loss: 0.6818 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5012 - loss: 0.6823 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4972 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5006 - loss: 0.6818 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4989 - loss: 0.6810 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5020 - loss: 0.6820 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4973 - loss: 0.6822 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4996 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4980 - loss: 0.6819 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4988 - loss: 0.6814 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma4_drop4_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5015 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4950 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6831 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4990 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6831 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4987 - loss: 0.6818 - val_AUC: 0.5000 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4981 - loss: 0.6807 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4978 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4971 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4992 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4993 - loss: 0.6812 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.5009 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4979 - loss: 0.6806 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4998 - loss: 0.6811 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma4_drop5_drop.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.4977 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6830 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4963 - loss: 0.6826 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5001 - loss: 0.6826 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4981 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4990 - loss: 0.6826 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4970 - loss: 0.6820 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5001 - loss: 0.6816 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5000 - loss: 0.6818 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 2.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2282/2282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4994 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6827 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed_sigma4_drop5_replace.csv as the input file.\n",
      "Epoch 1/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - AUC: 0.5018 - loss: 0.6821 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5056 - loss: 0.6806 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4998 - loss: 0.6813 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5006 - loss: 0.6814 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - AUC: 0.4947 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.5034 - loss: 0.6814 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4974 - loss: 0.6808 - val_AUC: 0.5000 - val_loss: 0.6828 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2478/2478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - AUC: 0.4996 - loss: 0.6817 - val_AUC: 0.5000 - val_loss: 0.6829 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     train_model(file)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, roc_auc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Neural Network ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - ROC - 0.0589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2478/2478 - 4s - 2ms/step - AUC: 0.8308 - loss: 0.4878 - val_AUC: 0.8443 - val_loss: 0.4921\n",
      "Epoch 2/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8439 - loss: 0.4712 - val_AUC: 0.8470 - val_loss: 0.4702\n",
      "Epoch 3/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8467 - loss: 0.4680 - val_AUC: 0.8435 - val_loss: 0.4751\n",
      "Epoch 4/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8475 - loss: 0.4667 - val_AUC: 0.8490 - val_loss: 0.4706\n",
      "Epoch 5/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8478 - loss: 0.4660 - val_AUC: 0.8488 - val_loss: 0.4660\n",
      "Epoch 6/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8487 - loss: 0.4652 - val_AUC: 0.8484 - val_loss: 0.4666\n",
      "Epoch 7/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8490 - loss: 0.4644 - val_AUC: 0.8491 - val_loss: 0.4723\n",
      "Epoch 8/100\n",
      "2478/2478 - 2s - 1ms/step - AUC: 0.8493 - loss: 0.4642 - val_AUC: 0.8495 - val_loss: 0.4649\n",
      "Epoch 9/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8497 - loss: 0.4631 - val_AUC: 0.8499 - val_loss: 0.4644\n",
      "Epoch 10/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8494 - loss: 0.4637 - val_AUC: 0.8505 - val_loss: 0.4635\n",
      "Epoch 11/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8496 - loss: 0.4634 - val_AUC: 0.8506 - val_loss: 0.4642\n",
      "Epoch 12/100\n",
      "2478/2478 - 2s - 1ms/step - AUC: 0.8502 - loss: 0.4628 - val_AUC: 0.8495 - val_loss: 0.4682\n",
      "Epoch 13/100\n",
      "2478/2478 - 2s - 1ms/step - AUC: 0.8503 - loss: 0.4623 - val_AUC: 0.8504 - val_loss: 0.4638\n",
      "Epoch 14/100\n",
      "2478/2478 - 2s - 1ms/step - AUC: 0.8497 - loss: 0.4631 - val_AUC: 0.8507 - val_loss: 0.4739\n",
      "Epoch 15/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8501 - loss: 0.4626 - val_AUC: 0.8505 - val_loss: 0.4641\n",
      "Epoch 16/100\n",
      "2478/2478 - 2s - 994us/step - AUC: 0.8504 - loss: 0.4623 - val_AUC: 0.8506 - val_loss: 0.4657\n",
      "Epoch 17/100\n",
      "2478/2478 - 2s - 998us/step - AUC: 0.8505 - loss: 0.4623 - val_AUC: 0.8506 - val_loss: 0.4646\n",
      "Epoch 18/100\n",
      "2478/2478 - 2s - 1ms/step - AUC: 0.8504 - loss: 0.4624 - val_AUC: 0.8498 - val_loss: 0.4693\n",
      "Epoch 19/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8509 - loss: 0.4617 - val_AUC: 0.8511 - val_loss: 0.4650\n",
      "Epoch 20/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8503 - loss: 0.4625 - val_AUC: 0.8507 - val_loss: 0.4646\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step\n",
      "Neural Network ROC AUC: 0.8505433059823326\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(21, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(21, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "# model2.add(Dense(10, activation='relu'))\n",
    "# model2.add(Dense(5, activation='relu'))\n",
    "# model2.add(Dense(3, activation='relu'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train, y_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model2.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 617us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model2.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2478/2478 - 5s - 2ms/step - AUC: 0.8265 - loss: 0.4922 - val_AUC: 0.8416 - val_loss: 0.4800\n",
      "Epoch 2/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8407 - loss: 0.4757 - val_AUC: 0.8450 - val_loss: 0.4735\n",
      "Epoch 3/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8435 - loss: 0.4721 - val_AUC: 0.8480 - val_loss: 0.4676\n",
      "Epoch 4/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8451 - loss: 0.4704 - val_AUC: 0.8484 - val_loss: 0.4676\n",
      "Epoch 5/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8467 - loss: 0.4685 - val_AUC: 0.8481 - val_loss: 0.4753\n",
      "Epoch 6/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8473 - loss: 0.4673 - val_AUC: 0.8492 - val_loss: 0.4666\n",
      "Epoch 7/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8475 - loss: 0.4671 - val_AUC: 0.8494 - val_loss: 0.4654\n",
      "Epoch 8/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8485 - loss: 0.4659 - val_AUC: 0.8495 - val_loss: 0.4653\n",
      "Epoch 9/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8477 - loss: 0.4670 - val_AUC: 0.8491 - val_loss: 0.4665\n",
      "Epoch 10/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8483 - loss: 0.4658 - val_AUC: 0.8483 - val_loss: 0.4677\n",
      "Epoch 11/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8483 - loss: 0.4658 - val_AUC: 0.8493 - val_loss: 0.4654\n",
      "Epoch 12/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8489 - loss: 0.4651 - val_AUC: 0.8464 - val_loss: 0.4709\n",
      "Epoch 13/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8489 - loss: 0.4650 - val_AUC: 0.8500 - val_loss: 0.4648\n",
      "Epoch 14/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8492 - loss: 0.4645 - val_AUC: 0.8503 - val_loss: 0.4654\n",
      "Epoch 15/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8493 - loss: 0.4644 - val_AUC: 0.8504 - val_loss: 0.4646\n",
      "Epoch 16/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8498 - loss: 0.4636 - val_AUC: 0.8502 - val_loss: 0.4643\n",
      "Epoch 17/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8499 - loss: 0.4634 - val_AUC: 0.8504 - val_loss: 0.4668\n",
      "Epoch 18/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8498 - loss: 0.4635 - val_AUC: 0.8496 - val_loss: 0.4705\n",
      "Epoch 19/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8497 - loss: 0.4637 - val_AUC: 0.8504 - val_loss: 0.4645\n",
      "Epoch 20/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8499 - loss: 0.4633 - val_AUC: 0.8505 - val_loss: 0.4636\n",
      "Epoch 21/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8504 - loss: 0.4629 - val_AUC: 0.8484 - val_loss: 0.4671\n",
      "Epoch 22/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8500 - loss: 0.4633 - val_AUC: 0.8486 - val_loss: 0.4666\n",
      "Epoch 23/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8497 - loss: 0.4635 - val_AUC: 0.8512 - val_loss: 0.4644\n",
      "Epoch 24/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8500 - loss: 0.4633 - val_AUC: 0.8511 - val_loss: 0.4642\n",
      "Epoch 25/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8494 - loss: 0.4639 - val_AUC: 0.8507 - val_loss: 0.4643\n",
      "Epoch 26/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8499 - loss: 0.4632 - val_AUC: 0.8511 - val_loss: 0.4637\n",
      "Epoch 27/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8500 - loss: 0.4631 - val_AUC: 0.8508 - val_loss: 0.4639\n",
      "Epoch 28/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8496 - loss: 0.4635 - val_AUC: 0.8509 - val_loss: 0.4638\n",
      "Epoch 29/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8506 - loss: 0.4623 - val_AUC: 0.8509 - val_loss: 0.4635\n",
      "Epoch 30/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8504 - loss: 0.4625 - val_AUC: 0.8509 - val_loss: 0.4637\n",
      "Epoch 31/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8503 - loss: 0.4630 - val_AUC: 0.8518 - val_loss: 0.4647\n",
      "Epoch 32/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8506 - loss: 0.4624 - val_AUC: 0.8502 - val_loss: 0.4643\n",
      "Epoch 33/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8506 - loss: 0.4625 - val_AUC: 0.8504 - val_loss: 0.4645\n",
      "Epoch 34/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8504 - loss: 0.4624 - val_AUC: 0.8506 - val_loss: 0.4673\n",
      "Epoch 35/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8507 - loss: 0.4618 - val_AUC: 0.8517 - val_loss: 0.4626\n",
      "Epoch 36/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8503 - loss: 0.4626 - val_AUC: 0.8517 - val_loss: 0.4622\n",
      "Epoch 37/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8505 - loss: 0.4622 - val_AUC: 0.8516 - val_loss: 0.4629\n",
      "Epoch 38/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8505 - loss: 0.4624 - val_AUC: 0.8513 - val_loss: 0.4631\n",
      "Epoch 39/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8505 - loss: 0.4622 - val_AUC: 0.8503 - val_loss: 0.4647\n",
      "Epoch 40/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8503 - loss: 0.4624 - val_AUC: 0.8518 - val_loss: 0.4630\n",
      "Epoch 41/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8507 - loss: 0.4621 - val_AUC: 0.8513 - val_loss: 0.4627\n",
      "Epoch 42/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8508 - loss: 0.4620 - val_AUC: 0.8509 - val_loss: 0.4651\n",
      "Epoch 43/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8504 - loss: 0.4624 - val_AUC: 0.8515 - val_loss: 0.4650\n",
      "Epoch 44/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8506 - loss: 0.4623 - val_AUC: 0.8513 - val_loss: 0.4632\n",
      "Epoch 45/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8510 - loss: 0.4618 - val_AUC: 0.8514 - val_loss: 0.4624\n",
      "Epoch 46/100\n",
      "2478/2478 - 3s - 1ms/step - AUC: 0.8511 - loss: 0.4617 - val_AUC: 0.8508 - val_loss: 0.4636\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step\n",
      "Neural Network ROC AUC: 0.8516899564501222\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(21, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(21, activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(5, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "# model2.add(Dense(10, activation='relu'))\n",
    "# model2.add(Dense(5, activation='relu'))\n",
    "# model2.add(Dense(3, activation='relu'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train, y_train, epochs=100, batch_size=64,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model2.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model2.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - z chata - ROC 0.85316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 7s - 1ms/step - AUC: 0.8287 - loss: 0.5240 - val_AUC: 0.8385 - val_loss: 0.4959 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8352 - loss: 0.4932 - val_AUC: 0.8405 - val_loss: 0.4951 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8373 - loss: 0.4908 - val_AUC: 0.8434 - val_loss: 0.5011 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8374 - loss: 0.4906 - val_AUC: 0.8414 - val_loss: 0.4944 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8373 - loss: 0.4899 - val_AUC: 0.8419 - val_loss: 0.4925 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8374 - loss: 0.4899 - val_AUC: 0.8358 - val_loss: 0.4929 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4893 - val_AUC: 0.8390 - val_loss: 0.4937 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8377 - loss: 0.4894 - val_AUC: 0.8407 - val_loss: 0.4961 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8380 - loss: 0.4886 - val_AUC: 0.8367 - val_loss: 0.4911 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8381 - loss: 0.4882 - val_AUC: 0.8375 - val_loss: 0.5164 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8378 - loss: 0.4886 - val_AUC: 0.8334 - val_loss: 0.5001 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8371 - loss: 0.4891 - val_AUC: 0.8414 - val_loss: 0.5105 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8381 - loss: 0.4875 - val_AUC: 0.8364 - val_loss: 0.5188 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4878 - val_AUC: 0.8425 - val_loss: 0.5044 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8380 - loss: 0.4877 - val_AUC: 0.8419 - val_loss: 0.4832 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8388 - loss: 0.4864 - val_AUC: 0.8309 - val_loss: 0.5387 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8377 - loss: 0.4881 - val_AUC: 0.8393 - val_loss: 0.4911 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8386 - loss: 0.4868 - val_AUC: 0.8396 - val_loss: 0.4901 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4881 - val_AUC: 0.8250 - val_loss: 0.5455 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8381 - loss: 0.4874 - val_AUC: 0.8432 - val_loss: 0.4935 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8377 - loss: 0.4881 - val_AUC: 0.8430 - val_loss: 0.4847 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4877 - val_AUC: 0.8431 - val_loss: 0.4881 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8382 - loss: 0.4871 - val_AUC: 0.8406 - val_loss: 0.4885 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8388 - loss: 0.4865 - val_AUC: 0.8427 - val_loss: 0.4873 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8378 - loss: 0.4876 - val_AUC: 0.8354 - val_loss: 0.5161 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8381 - loss: 0.4873 - val_AUC: 0.8407 - val_loss: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8382 - loss: 0.4871 - val_AUC: 0.8429 - val_loss: 0.5104 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8385 - loss: 0.4868 - val_AUC: 0.8439 - val_loss: 0.4925 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8382 - loss: 0.4867 - val_AUC: 0.8417 - val_loss: 0.4845 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8383 - loss: 0.4871 - val_AUC: 0.8393 - val_loss: 0.4877 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8381 - loss: 0.4874 - val_AUC: 0.8391 - val_loss: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8378 - loss: 0.4872 - val_AUC: 0.8396 - val_loss: 0.4881 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8384 - loss: 0.4869 - val_AUC: 0.8354 - val_loss: 0.4987 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4872 - val_AUC: 0.8434 - val_loss: 0.4860 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8386 - loss: 0.4867 - val_AUC: 0.8440 - val_loss: 0.4830 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8377 - loss: 0.4872 - val_AUC: 0.8413 - val_loss: 0.4973 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8370 - loss: 0.4881 - val_AUC: 0.8430 - val_loss: 0.4867 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8383 - loss: 0.4869 - val_AUC: 0.8375 - val_loss: 0.5006 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8380 - loss: 0.4874 - val_AUC: 0.8402 - val_loss: 0.5197 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8375 - loss: 0.4877 - val_AUC: 0.8390 - val_loss: 0.4872 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8379 - loss: 0.4873 - val_AUC: 0.8379 - val_loss: 0.4884 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8377 - loss: 0.4875 - val_AUC: 0.8423 - val_loss: 0.4859 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8372 - loss: 0.4882 - val_AUC: 0.8227 - val_loss: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8382 - loss: 0.4870 - val_AUC: 0.8410 - val_loss: 0.4981 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8374 - loss: 0.4880 - val_AUC: 0.8452 - val_loss: 0.4872 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8379 - loss: 0.4870 - val_AUC: 0.8416 - val_loss: 0.4867 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8384 - loss: 0.4868 - val_AUC: 0.8443 - val_loss: 0.4839 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8381 - loss: 0.4870 - val_AUC: 0.8327 - val_loss: 0.5027 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8377 - loss: 0.4874 - val_AUC: 0.8408 - val_loss: 0.4862 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8382 - loss: 0.4868 - val_AUC: 0.8366 - val_loss: 0.5136 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8384 - loss: 0.4867 - val_AUC: 0.8286 - val_loss: 0.4988 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8380 - loss: 0.4865 - val_AUC: 0.8428 - val_loss: 0.4875 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "4956/4956 - 5s - 1ms/step - AUC: 0.8379 - loss: 0.4871 - val_AUC: 0.8409 - val_loss: 0.4846 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8382 - loss: 0.4869 - val_AUC: 0.8405 - val_loss: 0.4990 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "4956/4956 - 6s - 1ms/step - AUC: 0.8378 - loss: 0.4871 - val_AUC: 0.8434 - val_loss: 0.4872 - learning_rate: 0.0010\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step\n",
      "Neural Network ROC AUC: 0.8440101344371734\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define the model\n",
    "model2 = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, kernel_regularizer=l2(0.01)),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_prob = model2.predict(X_val)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model2.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"NN - temp.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(\"NN - temp.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming `model2` is your trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_temp.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Saves to the SavedModel format by default\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming `model2` is your trained model\n",
    "model2.save('model_temp.keras')  # Saves to the SavedModel format by default\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('model_temp.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'as_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make sure your model is defined and loaded with the trained weights\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the SHAP Deep Explainer\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Using a subset of training data as background\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Compute SHAP values on a subset of validation data for speed reasons\u001b[39;00m\n\u001b[0;32m     10\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_val[:\u001b[38;5;241m100\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:90\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, masker)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:172\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_symbolics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     noutputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_list\u001b[49m()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m noutputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_symbolics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(noutputs)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'as_list'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Make sure your model is defined and loaded with the trained weights\n",
    "\n",
    "# Initialize the SHAP Deep Explainer\n",
    "explainer = shap.DeepExplainer(model2, X_train[:100])  # Using a subset of training data as background\n",
    "\n",
    "# Compute SHAP values on a subset of validation data for speed reasons\n",
    "shap_values = explainer.shap_values(X_val[:100])\n",
    "\n",
    "# Plot the summary plot for the first class (binary classification)\n",
    "shap.summary_plot(shap_values[0], X_val[:100], feature_names=X_val.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:01<00:50,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:01<00:50,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:02<00:49,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:02<00:48,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:03<00:47,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:03<00:46,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:04<00:45,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:04<00:46,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:05<00:46,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:05<00:45,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:06<00:44,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:06<00:43,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:07<00:43,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:07<00:42,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:08<00:41,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:08<00:41,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:09<00:40,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:09<00:40,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:10<00:39,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:10<00:39,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:11<00:38,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:11<00:38,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:12<00:37,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:12<00:36,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:13<00:36,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:13<00:35,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:14<00:35,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:14<00:35,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:15<00:34,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:15<00:34,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:16<00:33,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:16<00:33,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:17<00:33,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:17<00:32,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:18<00:31,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:18<00:30,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:19<00:30,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:19<00:30,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:20<00:30,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:20<00:29,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [00:21<00:28,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [00:21<00:28,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:22<00:28,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:22<00:27,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:23<00:27,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:23<00:26,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:24<00:26,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:24<00:25,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:25<00:25,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:25<00:25,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:26<00:24,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:26<00:24,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:27<00:23,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:27<00:22,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [00:28<00:22,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:28<00:22,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [00:29<00:21,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:29<00:20,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:30<00:20,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:30<00:19,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:31<00:19,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:31<00:18,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:32<00:18,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:32<00:17,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [00:33<00:17,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:33<00:16,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:34<00:15,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [00:34<00:15,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [00:35<00:14,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:35<00:14,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:36<00:13,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:36<00:13,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [00:37<00:12,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:37<00:12,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [00:38<00:12,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:38<00:11,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:39<00:11,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:39<00:10,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:40<00:09,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:40<00:09,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [00:41<00:08,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:41<00:08,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:42<00:07,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [00:42<00:07,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [00:43<00:06,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:43<00:06,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [00:44<00:05,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:44<00:05,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:45<00:04,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:45<00:04,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:46<00:03,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:46<00:03,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:47<00:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [00:47<00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [00:48<00:02,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:48<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [00:49<00:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:49<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  2.00it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Use KernelExplainer as an alternative\n",
    "explainer = shap.KernelExplainer(model2.predict, shap.sample(X_train, 100))\n",
    "shap_values = explainer.shap_values(shap.sample(X_val, 100), nsamples=100)  # Limit samples to manage computation\n",
    "\n",
    "# Plot the SHAP values\n",
    "shap.summary_plot(shap_values, shap.sample(X_val, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "  warnings.warn(\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'as_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmodel2\u001b[38;5;241m.\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39mmodel2\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Now use DeepExplainer with the logit model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_val[:\u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m      9\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values[\u001b[38;5;241m0\u001b[39m], X_val[:\u001b[38;5;241m100\u001b[39m], feature_names\u001b[38;5;241m=\u001b[39mX_val\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:90\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, masker)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:172\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_symbolics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     noutputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_list\u001b[49m()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m noutputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_symbolics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(noutputs)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'as_list'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Create a new model that outputs logits if your original model ends with a sigmoid activation\n",
    "logit_model = Model(inputs=model2.inputs, outputs=model2.layers[-2].output)\n",
    "\n",
    "# Now use DeepExplainer with the logit model\n",
    "explainer = shap.DeepExplainer(logit_model, X_train[:100])\n",
    "shap_values = explainer.shap_values(X_val[:100])\n",
    "shap.summary_plot(shap_values[0], X_val[:100], feature_names=X_val.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 650us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:07<12:25,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:14<11:49,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:21<11:35,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:28<11:15,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:35<11:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:42<10:48,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:49<10:44,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 623us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:55<10:33,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:02<10:24,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:09<10:18,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:16<10:11,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:23<10:08,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:30<09:59,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:37<09:50,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:44<09:45,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:51<09:40,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:57<09:29,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:04<09:21,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:11<09:12,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:18<09:03,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 649us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [02:25<09:02,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [02:31<08:52,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [02:38<08:43,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 616us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [02:45<08:35,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [02:52<08:33,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 666us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:59<08:38,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:06<08:26,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [03:13<08:18,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [03:20<08:09,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [03:27<08:02,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 674us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [03:34<08:00,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [03:41<07:51,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [03:47<07:42,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [03:54<07:38,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [04:01<07:29,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 627us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [04:08<07:23,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [04:15<07:16,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 677us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [04:22<07:15,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 613us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [04:29<07:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 650us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [04:36<06:56,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [04:43<06:46,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [04:50<06:36,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [04:56<06:28,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 610us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [05:03<06:19,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 611us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [05:10<06:11,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [05:17<06:06,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [05:24<06:02,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 681us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [05:31<06:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [05:38<05:52,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [05:45<05:49,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 628us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [05:52<05:39,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [05:58<05:32,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 615us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [06:05<05:23,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [06:12<05:16,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 627us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [06:19<05:10,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [06:26<05:02,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [06:33<04:55,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [06:40<04:47,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 638us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [06:47<04:42,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 640us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [06:53<04:35,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [07:00<04:27,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 627us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [07:07<04:20,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 613us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [07:14<04:12,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 623us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [07:21<04:05,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [07:28<04:00,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 628us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [07:34<03:53,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [07:41<03:45,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [07:48<03:37,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 647us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [07:55<03:32,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 650us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [08:02<03:26,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [08:09<03:20,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [08:16<03:13,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [08:23<03:07,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 635us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [08:30<03:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 695us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [08:37<02:56,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [08:44<02:48,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 643us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [08:51<02:41,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 632us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [08:58<02:33,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [09:05<02:26,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [09:12<02:18,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [09:19<02:11,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 633us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [09:25<02:04,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [09:32<01:58,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 669us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [09:40<01:52,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [09:47<01:45,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 678us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [09:54<01:40,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [10:02<01:35,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 704us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [10:09<01:27,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [10:16<01:20,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [10:24<01:12,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 640us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [10:31<01:04,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [10:38<00:57,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 651us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [10:45<00:49,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [10:52<00:43,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 693us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [10:59<00:36,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [11:06<00:28,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 639us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [11:14<00:21,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [11:21<00:14,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:28<00:07,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m6532/6532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [11:35<00:00,  6.95s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Dependence plot for a specific feature\u001b[39;00m\n\u001b[0;32m     15\u001b[0m feature_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Change index based on feature of interest\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdependence_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Force plot for a single prediction\u001b[39;00m\n\u001b[0;32m     19\u001b[0m instance_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Change index to explore other predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\plots\\_scatter.py:572\u001b[0m, in \u001b[0;36mdependence_legacy\u001b[1;34m(ind, shap_values, features, feature_names, display_features, interaction_index, color, axis_color, cmap, dot_size, x_jitter, alpha, title, xmin, xmax, ax, show, ymin, ymax)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ind, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m interaction_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 572\u001b[0m         interaction_index \u001b[38;5;241m=\u001b[39m \u001b[43mapproximate_interactions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    573\u001b[0m     interaction_index \u001b[38;5;241m=\u001b[39m convert_name(interaction_index, shap_values, feature_names)\n\u001b[0;32m    574\u001b[0m categorical_interaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\utils\\_general.py:135\u001b[0m, in \u001b[0;36mapproximate_interactions\u001b[1;34m(index, shap_values, X, feature_names)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(x), inc):\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(val_other[j:j \u001b[38;5;241m+\u001b[39m inc]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(shap_ref[j:j \u001b[38;5;241m+\u001b[39m inc]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m             v \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_ref\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_other\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    136\u001b[0m val_v \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    138\u001b[0m val_other \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(encoded_val_other)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2889\u001b[0m, in \u001b[0;36mcorrcoef\u001b[1;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[0;32m   2885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[0;32m   2886\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[0;32m   2887\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2888\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2889\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2891\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2683\u001b[0m, in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rowvar \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2682\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 2683\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 10"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Use KernelExplainer with a representative sample\n",
    "background = shap.sample(X_train, 100)  # Adjust size based on your dataset and compute capacity\n",
    "explainer = shap.KernelExplainer(model2.predict, background)\n",
    "\n",
    "# Calculate SHAP values for a sample of the validation data\n",
    "val_sample = shap.sample(X_val, 100)  # Keeping it manageable\n",
    "shap_values = explainer.shap_values(val_sample, nsamples='auto')\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, val_sample, feature_names=X_val.columns)\n",
    "\n",
    "# Dependence plot for a specific feature\n",
    "feature_index = 1  # Change index based on feature of interest\n",
    "shap.dependence_plot(feature_index, shap_values, val_sample, feature_names=X_val.columns)\n",
    "\n",
    "# Force plot for a single prediction\n",
    "instance_index = 0  # Change index to explore other predictions\n",
    "shap.force_plot(explainer.expected_value, shap_values[instance_index,:], val_sample.iloc[instance_index,:], feature_names=X_val.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
