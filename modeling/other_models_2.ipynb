{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using unpreprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     0\n",
      "age                    0\n",
      "height(cm)             0\n",
      "weight(kg)             0\n",
      "waist(cm)              0\n",
      "eyesight(left)         0\n",
      "eyesight(right)        0\n",
      "hearing(left)          0\n",
      "hearing(right)         0\n",
      "systolic               0\n",
      "relaxation             0\n",
      "fasting blood sugar    0\n",
      "Cholesterol            0\n",
      "triglyceride           0\n",
      "HDL                    0\n",
      "LDL                    0\n",
      "hemoglobin             0\n",
      "Urine protein          0\n",
      "serum creatinine       0\n",
      "AST                    0\n",
      "ALT                    0\n",
      "Gtp                    0\n",
      "dental caries          0\n",
      "smoking                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Fill missing values or drop them\n",
    "train_data.fillna(train_data.median(), inplace=True)\n",
    "\n",
    "# Encoding categorical variables if necessary\n",
    "# Here, I'm assuming there are categorical variables. Adjust as per your dataset.\n",
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "# Ensure train and test data have the same columns\n",
    "# train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('smoking', axis=1)\n",
    "y = train_data['smoking']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 0.38725767399198574\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, y_pred_xgb))\n",
    "print(f'XGBoost RMSE: {xgb_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     22\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get the best parameters\u001b[39;00m\n\u001b[0;32m     29\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_xgb_model = XGBRegressor(**best_params, random_state=42)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_xgb_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - 0.80623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 - 5s - 1ms/step - AUC: 0.5791 - loss: 25.4712 - val_AUC: 0.6353 - val_loss: 5.3111\n",
      "Epoch 2/100\n",
      "3982/3982 - 4s - 931us/step - AUC: 0.6295 - loss: 5.8477 - val_AUC: 0.7828 - val_loss: 1.4889\n",
      "Epoch 3/100\n",
      "3982/3982 - 4s - 909us/step - AUC: 0.6478 - loss: 4.3028 - val_AUC: 0.5896 - val_loss: 6.2866\n",
      "Epoch 4/100\n",
      "3982/3982 - 4s - 920us/step - AUC: 0.6593 - loss: 2.8470 - val_AUC: 0.6928 - val_loss: 2.1983\n",
      "Epoch 5/100\n",
      "3982/3982 - 4s - 902us/step - AUC: 0.6697 - loss: 1.7914 - val_AUC: 0.6107 - val_loss: 2.8768\n",
      "Epoch 6/100\n",
      "3982/3982 - 4s - 906us/step - AUC: 0.6945 - loss: 1.1439 - val_AUC: 0.7955 - val_loss: 0.5918\n",
      "Epoch 7/100\n",
      "3982/3982 - 4s - 909us/step - AUC: 0.6996 - loss: 0.6693 - val_AUC: 0.5453 - val_loss: 0.6778\n",
      "Epoch 8/100\n",
      "3982/3982 - 4s - 908us/step - AUC: 0.5928 - loss: 0.6743 - val_AUC: 0.5315 - val_loss: 0.6778\n",
      "Epoch 9/100\n",
      "3982/3982 - 4s - 891us/step - AUC: 0.5335 - loss: 0.6777 - val_AUC: 0.5187 - val_loss: 0.6817\n",
      "Epoch 10/100\n",
      "3982/3982 - 4s - 907us/step - AUC: 0.5130 - loss: 0.6811 - val_AUC: 0.5179 - val_loss: 0.6817\n",
      "Epoch 11/100\n",
      "3982/3982 - 4s - 904us/step - AUC: 0.5083 - loss: 0.6863 - val_AUC: 0.5100 - val_loss: 0.6841\n",
      "Epoch 12/100\n",
      "3982/3982 - 4s - 906us/step - AUC: 0.5164 - loss: 0.6814 - val_AUC: 0.5161 - val_loss: 0.6825\n",
      "Epoch 13/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5204 - loss: 0.6816 - val_AUC: 0.5123 - val_loss: 0.6834\n",
      "Epoch 14/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5199 - loss: 0.6818 - val_AUC: 0.5143 - val_loss: 0.6829\n",
      "Epoch 15/100\n",
      "3982/3982 - 4s - 914us/step - AUC: 0.5100 - loss: 0.6824 - val_AUC: 0.5097 - val_loss: 0.6839\n",
      "Epoch 16/100\n",
      "3982/3982 - 4s - 933us/step - AUC: 0.5247 - loss: 0.6881 - val_AUC: 0.5360 - val_loss: 0.6761\n",
      "\u001b[1m996/996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step\n",
      "Neural Network ROC AUC: 0.7955519927738477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(22, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>...</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159256</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>49</td>\n",
       "      <td>115</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159257</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>35</td>\n",
       "      <td>104</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159258</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>70</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>39</td>\n",
       "      <td>88</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159259</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>75</td>\n",
       "      <td>128</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159260</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>89.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106166</th>\n",
       "      <td>265422</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>149</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106167</th>\n",
       "      <td>265423</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>85</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>186</td>\n",
       "      <td>44</td>\n",
       "      <td>100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106168</th>\n",
       "      <td>265424</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>85</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>142</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106169</th>\n",
       "      <td>265425</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106170</th>\n",
       "      <td>265426</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106171 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0       159256   40         165          70       84.0             1.2   \n",
       "1       159257   80         160          60       93.0             1.0   \n",
       "2       159258   60         170          70       86.5             0.6   \n",
       "3       159259   40         160          50       67.0             0.3   \n",
       "4       159260   40         170          75       89.4             1.0   \n",
       "...        ...  ...         ...         ...        ...             ...   \n",
       "106166  265422   40         165          60       78.0             0.8   \n",
       "106167  265423   40         170          85       95.0             1.2   \n",
       "106168  265424   35         170          85       89.0             1.2   \n",
       "106169  265425   40         160          60       67.0             0.7   \n",
       "106170  265426   50         150          50       80.0             0.9   \n",
       "\n",
       "        eyesight(right)  hearing(left)  hearing(right)  systolic  ...  \\\n",
       "0                   1.2              1               1       130  ...   \n",
       "1                   1.0              2               2       144  ...   \n",
       "2                   0.7              1               1       117  ...   \n",
       "3                   0.4              1               1       116  ...   \n",
       "4                   0.9              1               1       132  ...   \n",
       "...                 ...            ...             ...       ...  ...   \n",
       "106166              0.9              1               1       112  ...   \n",
       "106167              1.2              1               1       130  ...   \n",
       "106168              1.2              1               1       131  ...   \n",
       "106169              0.8              1               1       120  ...   \n",
       "106170              1.0              1               1       115  ...   \n",
       "\n",
       "        triglyceride  HDL  LDL  hemoglobin  Urine protein  serum creatinine  \\\n",
       "0                186   49  115        14.2              1               0.9   \n",
       "1                158   35  104        13.0              1               1.1   \n",
       "2                173   39   88        15.4              1               1.4   \n",
       "3                 47   75  128        14.5              1               0.6   \n",
       "4                100   39  123        16.5              1               1.0   \n",
       "...              ...  ...  ...         ...            ...               ...   \n",
       "106166            82   59  149        16.4              1               1.1   \n",
       "106167           186   44  100        16.0              2               1.0   \n",
       "106168            76   53  142        15.9              1               0.8   \n",
       "106169            81   55  103        13.9              1               0.6   \n",
       "106170            96   48  144        13.0              1               0.6   \n",
       "\n",
       "        AST  ALT  Gtp  dental caries  \n",
       "0        19   25   32              0  \n",
       "1        20   12   24              0  \n",
       "2        38   60   36              0  \n",
       "3        25   18   10              1  \n",
       "4        30   39   27              1  \n",
       "...     ...  ...  ...            ...  \n",
       "106166   24   31   28              0  \n",
       "106167   25   31   38              0  \n",
       "106168   33   32   24              1  \n",
       "106169   42   36   32              0  \n",
       "106170   18   11   17              1  \n",
       "\n",
       "[106171 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 609us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - 0.83979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3982 - 8s - 2ms/step - AUC: 0.6268 - loss: 0.6707 - val_AUC: 0.8002 - val_loss: 0.5510 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7553 - loss: 0.5759 - val_AUC: 0.8159 - val_loss: 0.5127 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.7785 - loss: 0.5531 - val_AUC: 0.7961 - val_loss: 0.5891 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7860 - loss: 0.5439 - val_AUC: 0.8061 - val_loss: 0.5647 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7917 - loss: 0.5383 - val_AUC: 0.7962 - val_loss: 0.7078 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.7948 - loss: 0.5338 - val_AUC: 0.8258 - val_loss: 0.4954 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.7976 - loss: 0.5302 - val_AUC: 0.8262 - val_loss: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8010 - loss: 0.5263 - val_AUC: 0.8216 - val_loss: 0.5338 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8024 - loss: 0.5247 - val_AUC: 0.8028 - val_loss: 0.6520 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8037 - loss: 0.5231 - val_AUC: 0.8265 - val_loss: 0.5054 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8045 - loss: 0.5219 - val_AUC: 0.8260 - val_loss: 0.5135 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8106 - loss: 0.5124 - val_AUC: 0.8270 - val_loss: 0.5008 - learning_rate: 2.0000e-04\n",
      "Epoch 13/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8113 - loss: 0.5114 - val_AUC: 0.8289 - val_loss: 0.4929 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8123 - loss: 0.5107 - val_AUC: 0.8225 - val_loss: 0.5192 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8127 - loss: 0.5102 - val_AUC: 0.8292 - val_loss: 0.4955 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8122 - loss: 0.5105 - val_AUC: 0.8285 - val_loss: 0.4971 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8132 - loss: 0.5099 - val_AUC: 0.8270 - val_loss: 0.5037 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8129 - loss: 0.5105 - val_AUC: 0.8263 - val_loss: 0.5081 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8134 - loss: 0.5088 - val_AUC: 0.8297 - val_loss: 0.4919 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8146 - loss: 0.5080 - val_AUC: 0.8301 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8148 - loss: 0.5068 - val_AUC: 0.8254 - val_loss: 0.5164 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8143 - loss: 0.5075 - val_AUC: 0.8302 - val_loss: 0.4918 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8151 - loss: 0.5071 - val_AUC: 0.8301 - val_loss: 0.4902 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8144 - loss: 0.5079 - val_AUC: 0.8304 - val_loss: 0.4896 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8148 - loss: 0.5072 - val_AUC: 0.8298 - val_loss: 0.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8148 - loss: 0.5073 - val_AUC: 0.8296 - val_loss: 0.4976 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8156 - loss: 0.5063 - val_AUC: 0.8298 - val_loss: 0.4907 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8152 - loss: 0.5065 - val_AUC: 0.8297 - val_loss: 0.4940 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8153 - loss: 0.5063 - val_AUC: 0.8306 - val_loss: 0.4895 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8165 - loss: 0.5044 - val_AUC: 0.8307 - val_loss: 0.4918 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8160 - loss: 0.5056 - val_AUC: 0.8308 - val_loss: 0.4911 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8159 - loss: 0.5054 - val_AUC: 0.8307 - val_loss: 0.4903 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8161 - loss: 0.5053 - val_AUC: 0.8309 - val_loss: 0.4924 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8163 - loss: 0.5059 - val_AUC: 0.8294 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8157 - loss: 0.5057 - val_AUC: 0.8313 - val_loss: 0.4897 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5044 - val_AUC: 0.8315 - val_loss: 0.4894 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8163 - loss: 0.5057 - val_AUC: 0.8311 - val_loss: 0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8160 - loss: 0.5049 - val_AUC: 0.8319 - val_loss: 0.4888 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8164 - loss: 0.5052 - val_AUC: 0.8320 - val_loss: 0.4875 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5048 - val_AUC: 0.8319 - val_loss: 0.4893 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8172 - loss: 0.5041 - val_AUC: 0.8318 - val_loss: 0.4885 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8180 - loss: 0.5032 - val_AUC: 0.8317 - val_loss: 0.4893 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "3982/3982 - 7s - 2ms/step - AUC: 0.8178 - loss: 0.5037 - val_AUC: 0.8314 - val_loss: 0.4895 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8179 - loss: 0.5032 - val_AUC: 0.8303 - val_loss: 0.4922 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8191 - loss: 0.5014 - val_AUC: 0.8305 - val_loss: 0.4943 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8172 - loss: 0.5042 - val_AUC: 0.8327 - val_loss: 0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8179 - loss: 0.5036 - val_AUC: 0.8334 - val_loss: 0.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8185 - loss: 0.5027 - val_AUC: 0.8332 - val_loss: 0.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8183 - loss: 0.5026 - val_AUC: 0.8334 - val_loss: 0.4864 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8191 - loss: 0.5022 - val_AUC: 0.8336 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8194 - loss: 0.5011 - val_AUC: 0.8332 - val_loss: 0.4868 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8196 - loss: 0.5009 - val_AUC: 0.8323 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8185 - loss: 0.5026 - val_AUC: 0.8320 - val_loss: 0.4949 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8186 - loss: 0.5029 - val_AUC: 0.8318 - val_loss: 0.4903 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8204 - loss: 0.5009 - val_AUC: 0.8331 - val_loss: 0.4917 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5012 - val_AUC: 0.8342 - val_loss: 0.4850 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8202 - loss: 0.5005 - val_AUC: 0.8349 - val_loss: 0.4840 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8204 - loss: 0.5005 - val_AUC: 0.8310 - val_loss: 0.5012 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8194 - loss: 0.5015 - val_AUC: 0.8345 - val_loss: 0.4845 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8212 - loss: 0.4996 - val_AUC: 0.8333 - val_loss: 0.4856 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8207 - loss: 0.5004 - val_AUC: 0.8341 - val_loss: 0.4874 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5007 - val_AUC: 0.8348 - val_loss: 0.4835 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8204 - loss: 0.5005 - val_AUC: 0.8297 - val_loss: 0.5040 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8202 - loss: 0.4998 - val_AUC: 0.8318 - val_loss: 0.4908 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8200 - loss: 0.5002 - val_AUC: 0.8353 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8199 - loss: 0.5005 - val_AUC: 0.8338 - val_loss: 0.4859 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8207 - loss: 0.4998 - val_AUC: 0.8351 - val_loss: 0.4842 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8219 - loss: 0.4988 - val_AUC: 0.8353 - val_loss: 0.4851 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8197 - loss: 0.5004 - val_AUC: 0.8355 - val_loss: 0.4831 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8221 - loss: 0.4979 - val_AUC: 0.8350 - val_loss: 0.4831 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8212 - loss: 0.4988 - val_AUC: 0.8358 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8215 - loss: 0.4988 - val_AUC: 0.8358 - val_loss: 0.4828 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8212 - loss: 0.4992 - val_AUC: 0.8356 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "3982/3982 - 6s - 2ms/step - AUC: 0.8214 - loss: 0.4992 - val_AUC: 0.8344 - val_loss: 0.4909 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "3982/3982 - 6s - 1ms/step - AUC: 0.8218 - loss: 0.4979 - val_AUC: 0.8340 - val_loss: 0.4892 - learning_rate: 1.0000e-04\n",
      "\u001b[1m996/996\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step\n",
      "Neural Network ROC AUC: 0.8353039739828398\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671us/step\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AUC', 'loss', 'val_AUC', 'val_loss', 'learning_rate'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation AUC values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['AUC'], label='Train AUC')\n",
    "plt.plot(history.history['val_AUC'], label='Val AUC')\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - ROC - ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "y_test_pred_prob = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - ROC - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7803905563229938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79     17783\n",
      "           1       0.73      0.80      0.76     14069\n",
      "\n",
      "    accuracy                           0.78     31852\n",
      "   macro avg       0.78      0.78      0.78     31852\n",
      "weighted avg       0.79      0.78      0.78     31852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the preprocessed csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                    0\n",
      "height(cm)             0\n",
      "weight(kg)             0\n",
      "waist(cm)              0\n",
      "systolic               0\n",
      "relaxation             0\n",
      "fasting blood sugar    0\n",
      "triglyceride           0\n",
      "HDL                    0\n",
      "LDL                    0\n",
      "hemoglobin             0\n",
      "Urine protein          0\n",
      "serum creatinine       0\n",
      "AST                    0\n",
      "ALT                    0\n",
      "Gtp                    0\n",
      "dental caries          0\n",
      "BMI                    0\n",
      "hearing                0\n",
      "eyesight               0\n",
      "AST/ALT_ratio          0\n",
      "smoking                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Fill missing values or drop them\n",
    "train_data.fillna(train_data.median(), inplace=True)\n",
    "\n",
    "# Encoding categorical variables if necessary\n",
    "# Here, I'm assuming there are categorical variables. Adjust as per your dataset.\n",
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "# Ensure train and test data have the same columns\n",
    "# train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('smoking', axis=1)\n",
    "y = train_data['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - NN - ROC - 0.85871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 9s - 2ms/step - AUC: 0.8098 - loss: 0.5155 - val_AUC: 0.8440 - val_loss: 0.4741 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8303 - loss: 0.4894 - val_AUC: 0.8452 - val_loss: 0.4712 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8330 - loss: 0.4868 - val_AUC: 0.8468 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8345 - loss: 0.4847 - val_AUC: 0.8481 - val_loss: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8347 - loss: 0.4839 - val_AUC: 0.8475 - val_loss: 0.4700 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8339 - loss: 0.4851 - val_AUC: 0.8483 - val_loss: 0.4679 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8355 - loss: 0.4837 - val_AUC: 0.8483 - val_loss: 0.4749 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8358 - loss: 0.4833 - val_AUC: 0.8484 - val_loss: 0.4687 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8365 - loss: 0.4820 - val_AUC: 0.8490 - val_loss: 0.4661 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8354 - loss: 0.4836 - val_AUC: 0.8488 - val_loss: 0.4663 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8370 - loss: 0.4815 - val_AUC: 0.8489 - val_loss: 0.4681 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8362 - loss: 0.4823 - val_AUC: 0.8485 - val_loss: 0.4683 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8364 - loss: 0.4822 - val_AUC: 0.8492 - val_loss: 0.4660 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8371 - loss: 0.4814 - val_AUC: 0.8475 - val_loss: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8378 - loss: 0.4803 - val_AUC: 0.8482 - val_loss: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8366 - loss: 0.4815 - val_AUC: 0.8482 - val_loss: 0.4665 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8386 - loss: 0.4796 - val_AUC: 0.8491 - val_loss: 0.4697 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8380 - loss: 0.4802 - val_AUC: 0.8494 - val_loss: 0.4671 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8388 - loss: 0.4792 - val_AUC: 0.8495 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4787 - val_AUC: 0.8495 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8403 - loss: 0.4775 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4786 - val_AUC: 0.8495 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4779 - val_AUC: 0.8495 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4775 - val_AUC: 0.8499 - val_loss: 0.4653 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4785 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4775 - val_AUC: 0.8497 - val_loss: 0.4646 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4775 - val_AUC: 0.8498 - val_loss: 0.4647 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8399 - loss: 0.4780 - val_AUC: 0.8499 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4776 - val_AUC: 0.8498 - val_loss: 0.4648 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8398 - loss: 0.4784 - val_AUC: 0.8498 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8404 - loss: 0.4773 - val_AUC: 0.8496 - val_loss: 0.4649 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8403 - loss: 0.4770 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4776 - val_AUC: 0.8500 - val_loss: 0.4643 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8405 - loss: 0.4773 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8402 - loss: 0.4778 - val_AUC: 0.8500 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8406 - loss: 0.4766 - val_AUC: 0.8499 - val_loss: 0.4644 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8401 - loss: 0.4778 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8409 - loss: 0.4769 - val_AUC: 0.8500 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8404 - loss: 0.4768 - val_AUC: 0.8501 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8398 - loss: 0.4778 - val_AUC: 0.8500 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4774 - val_AUC: 0.8499 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8407 - loss: 0.4767 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8406 - loss: 0.4768 - val_AUC: 0.8500 - val_loss: 0.4645 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step\n",
      "Neural Network ROC AUC: 0.8500097194665805\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - NN - ROC - 0.85812"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956/4956 - 10s - 2ms/step - AUC: 0.8141 - loss: 0.5094 - val_AUC: 0.8403 - val_loss: 0.4772 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8315 - loss: 0.4887 - val_AUC: 0.8471 - val_loss: 0.4692 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8330 - loss: 0.4869 - val_AUC: 0.8463 - val_loss: 0.4712 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8336 - loss: 0.4859 - val_AUC: 0.8474 - val_loss: 0.4688 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8343 - loss: 0.4850 - val_AUC: 0.8479 - val_loss: 0.4710 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8348 - loss: 0.4837 - val_AUC: 0.8475 - val_loss: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8354 - loss: 0.4838 - val_AUC: 0.8484 - val_loss: 0.4770 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8357 - loss: 0.4833 - val_AUC: 0.8471 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8357 - loss: 0.4827 - val_AUC: 0.8477 - val_loss: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8367 - loss: 0.4821 - val_AUC: 0.8488 - val_loss: 0.4672 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8367 - loss: 0.4817 - val_AUC: 0.8490 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8361 - loss: 0.4826 - val_AUC: 0.8481 - val_loss: 0.4682 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8367 - loss: 0.4819 - val_AUC: 0.8482 - val_loss: 0.4674 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8368 - loss: 0.4816 - val_AUC: 0.8492 - val_loss: 0.4675 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8370 - loss: 0.4819 - val_AUC: 0.8488 - val_loss: 0.4670 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8374 - loss: 0.4811 - val_AUC: 0.8490 - val_loss: 0.4659 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8371 - loss: 0.4813 - val_AUC: 0.8496 - val_loss: 0.4656 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8374 - loss: 0.4813 - val_AUC: 0.8492 - val_loss: 0.4668 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8365 - loss: 0.4821 - val_AUC: 0.8487 - val_loss: 0.4677 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8374 - loss: 0.4807 - val_AUC: 0.8483 - val_loss: 0.4758 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8370 - loss: 0.4814 - val_AUC: 0.8489 - val_loss: 0.4669 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8382 - loss: 0.4802 - val_AUC: 0.8488 - val_loss: 0.4767 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8384 - loss: 0.4799 - val_AUC: 0.8494 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8391 - loss: 0.4790 - val_AUC: 0.8495 - val_loss: 0.4652 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8386 - loss: 0.4800 - val_AUC: 0.8494 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8388 - loss: 0.4794 - val_AUC: 0.8493 - val_loss: 0.4656 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8387 - loss: 0.4797 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4790 - val_AUC: 0.8498 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8391 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4782 - val_AUC: 0.8496 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8387 - loss: 0.4792 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8380 - loss: 0.4802 - val_AUC: 0.8495 - val_loss: 0.4653 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4786 - val_AUC: 0.8495 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4791 - val_AUC: 0.8496 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8400 - loss: 0.4778 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "4956/4956 - 7s - 2ms/step - AUC: 0.8397 - loss: 0.4781 - val_AUC: 0.8497 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8387 - loss: 0.4798 - val_AUC: 0.8497 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8395 - loss: 0.4788 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4782 - val_AUC: 0.8496 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4784 - val_AUC: 0.8497 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "4956/4956 - 7s - 2ms/step - AUC: 0.8394 - loss: 0.4790 - val_AUC: 0.8497 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8397 - loss: 0.4783 - val_AUC: 0.8498 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8394 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "4956/4956 - 8s - 2ms/step - AUC: 0.8394 - loss: 0.4785 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4791 - val_AUC: 0.8497 - val_loss: 0.4651 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8393 - loss: 0.4791 - val_AUC: 0.8497 - val_loss: 0.4652 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8394 - loss: 0.4789 - val_AUC: 0.8498 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8390 - loss: 0.4789 - val_AUC: 0.8498 - val_loss: 0.4648 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8396 - loss: 0.4784 - val_AUC: 0.8497 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "4956/4956 - 7s - 1ms/step - AUC: 0.8392 - loss: 0.4789 - val_AUC: 0.8497 - val_loss: 0.4650 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step\n",
      "Neural Network ROC AUC: 0.8497395970013535\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# Define early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f'Neural Network ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3318/3318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = pd.read_csv('../data/test_data_preprocessed.csv')\n",
    "X_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "y_test_pred_prob = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],\n",
    "    'smoking': y_test_pred_prob.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN - MULTITHREADING - ROC - ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
